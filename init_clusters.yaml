# An unique identifier for the head node and workers of this cluster.
cluster_name: ray-cluster
max_workers: 3
# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled.
docker:
    image: "tardism/rayfl" # You can change this to latest-cpu if you don't need GPU support and want a faster startup
    # image: rayproject/ray:latest-cpu   # use this one if you don't need ML dependencies, it's faster to pull
    container_name: "ray_container"
    # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
    # if no cached version is present.
    pull_before_run: True
    # run_options:   # Extra options to pass into "docker run"
    #     - --ulimit nofile=65536:65536

    # Example of running a GPU head with CPU workers
    # head_image: "rayproject/ray-ml:latest-gpu"
    # Allow Ray to automatically detect GPUs

    # worker_image: "rayproject/ray-ml:latest-cpu"
    # worker_run_options: []

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 5

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-1
    cache_stopped_nodes: False

available_node_types:
    ray.head.default:
        resources: {}
        node_config:
            InstanceType: t2.medium
    ray.worker.default:
        resources: {}
        min_workers: 2
        max_workers: 3
        node_config:
            InstanceType: t2.medium
